% 04_two_view_geometry.tex
\documentclass[11pt,a4paper]{article}

\input{preamble.tex}
\title{Two-View Geometry}

\begin{document}
\maketitle

\section{Overview}

This document develops the mathematical foundations of two-view geometry.

Given two images of a static scene, our goals are:
\begin{itemize}
  \item Estimate the fundamental matrix
  \item Recover the relative camera pose
  \item Triangulate 3D points
\end{itemize}

\section{Camera Intrinsics and Extrinsics}

A pinhole camera maps 3D points in the world to 2D image coordinates via a projective transformation.
This mapping is parameterised by intrinsic and extrinsic components.

\subsection{Intrinsic Matrix}

The intrinsic matrix
\(
K \in \mathbb{R}^{3 \times 3}
\)
encodes the internal geometry of the camera, mapping camera-frame coordinates to pixel coordinates.

It is typically written as
\[
K =
\begin{bmatrix}
f_x & s   & c_x \\
0   & f_y & c_y \\
0   & 0   & 1
\end{bmatrix}
\]
where:
\begin{itemize}
  \item \(f_x, f_y\) are the focal lengths measured in pixels
  \item \(s\) is the skew parameter (usually zero)
  \item \((c_x, c_y)\) is the principal point
\end{itemize}

When working with normalised image coordinates, the effect of \(K\) is removed by pre-multiplying image points by \(K^{-1}\).

\subsection{Rotation}

The rotation matrix
\(
R \in SO(3)
\)
describes the orientation of the camera frame relative to the world frame.

It satisfies the defining properties:
\[
R^\top R = I, \quad \det(R) = 1
\]

Geometrically, \(R\) maps vectors from the world coordinate frame into the camera coordinate frame.

\subsection{Translation}

The translation vector
\(
t \in \mathbb{R}^3
\)
represents the position of the camera centre expressed in the camera coordinate frame.

Together with the rotation, it defines the rigid-body transformation between frames.

\subsection{Camera Projection Matrix}

The full camera projection matrix is \(P \in \mathbb{R}^{3 \times 4}\) given by
\[
P = K \,[\, R \mid t \,]
\]

A 3D point in homogeneous coordinates,
\[
X = (X, Y, Z, 1)^\top \in \mathbb{P}^3
\]
projects to an image point
\[
x \sim P X, \quad x \in \mathbb{P}^2
\]

\section{Two Views and Epipolar Geometry}

Consider two cameras observing the same 3D point \(X\):
\[
x_1 \sim P_1 X, \quad x_2 \sim P_2 X
\]

The camera centres and \(X\) define a plane in 3D known as the epipolar plane.
This plane intersects each image plane in a line, called an epipolar line.

The key geometric consequence is:

\begin{quote}
Given a point \(x_1\) in the first image, its correspondence \(x_2\) in the second image must lie on a specific line.
\end{quote}

This constraint is purely projective.

\section{The Fundamental Matrix}

The epipolar constraint can be written algebraically as
\[
x_2^\top F x_1 = 0
\]
where \(F \in \mathbb{R}^{3 \times 3}\) is the fundamental matrix.

\subsection{Properties}

The fundamental matrix satisfies:
\begin{itemize}
  \item \(F\) is defined up to scale
  \item \(\mathrm{rank}(F) = 2\)
  \item It maps points to epipolar lines: \(l_2 = F x_1\)
\end{itemize}

Geometrically, the constraint enforces that the vectors \(x_2\), \(F x_1\), and the origin are coplanar.

\section{Geometric Interpretation}

In the calibrated case, the fundamental matrix factors as
\[
F = [t]_\times R
\]
where \( [t]_\times \) is the skew-symmetric matrix of \(t\): 
\[
[t]_\times =
\begin{bmatrix}
0 & -t_z & t_y \\
t_z & 0 & -t_x \\
-t_y & t_x & 0
\end{bmatrix}
\]

The epipolar constraint
\[
x_2^\top [t]_\times R x_1 = 0
\]
expresses the fact that the two viewing rays and the translation vector lie in the same plane.

\section{Estimating the Fundamental Matrix}

Each point correspondence \((x_1, x_2)\) yields one linear constraint:
\[
x_2^\top F x_1 = 0
\]

Expanding this equation produces a linear system
\[
A f = 0
\]
where \(f = \mathrm{vec}(F)\)

With at least eight correspondences, the solution can be obtained, typically using Singular Value Decomposition (SVD).

\subsection{Rank-2 Enforcement}

The estimated matrix must satisfy: \(\det(F) = 0\)

This is enforced by:
\begin{enumerate}
  \item Computing the SVD \(F = U \Sigma V^\top\)
  \item Setting the smallest singular value to zero
  \item Reconstructing \(F\)
\end{enumerate}

This step restores the correct geometric structure.

\section{From Fundamental to Essential Matrix}

The fundamental matrix \(F\) encodes the epipolar geometry between two views n pixel coordinates. If the cameras are calibrated, we can factor out the intrinsic parameters and work in normalised image coordinates.

Let \(K_1, K_2\) denote the intrinsic calibration matrices of the two cameras.

Let \(x_1, x_2 \in \mathbb{P}^2\) denote corresponding points in pixel coordinates, we define the corresponding points in normalised camera coordinates
\[
\hat{x}_1 = K_1^{-1} x_1, \qquad \hat{x}_2 = K_2^{-1} x_2
\]

The epipolar constraint in pixel coordinates is
\(
x_2^\top F x_1 = 0
\)

Substituting \(x_i = K_i \hat{x}_i\) yields
\[
\hat{x}_2^\top \left( K_2^\top F K_1 \right) \hat{x}_1 = 0.
\]

By definition, the matrix multiplying the normalised coordinates is the
essential matrix:
\[
E = K_2^\top F K_1
\]

Equivalently, if the two cameras share the same intrinsics \(K\), this reduces to
\[
E = K^\top F K
\]

\paragraph{Geometric interpretation}
While the fundamental matrix operates on pixel coordinates, the essential matrix operates on normalised camera coordinates and therefore depends only on the relative pose between the cameras.

\paragraph{Algebraic properties}
The essential matrix satisfies the following constraints:
\begin{itemize}
  \item \(\mathrm{rank}(E) = 2\)
  \item \(E\) has two equal, nonzero singular values and one zero singular value
\end{itemize}

These constraints distinguish essential matrices from general \(3 \times 3\) matrices and must be enforced during estimation.

\paragraph{Pose factorisation}
The essential matrix admits the factorisation
\[
E = [t]_\times R
\]
Where 
\begin{itemize}
  \item \(R \in SO(3)\) is the relative rotation between the two camera frames
  \item \(t \in \mathbb{R}^3\) is the translation vector
  \item \([t]_\times\) denotes the skew-symmetric matrix corresponding to the cross product with \(t\)
\end{itemize}

From this factorisation, the relative camera pose can be recovered up to a four-fold ambiguity, which is resolved using cheirality constraints after triangulation.

\section{From Essential to Fundamental Matrix}

The essential matrix is defined as
\[
E = K_2^\top F K_1
\]

Rearranging, we obtain the inverse relationship
\[
F = K_2^{-\top} E K_1^{-1}
\]

\section{Recovering Camera Pose}

After enforcing the essential matrix constraints, the essential matrix admits the singular value decomposition
\[
E = U \Sigma V^\top,
\quad
\Sigma = \mathrm{diag}(1, 1, 0)
\]

Using the matrices
\[
W =
\begin{bmatrix}
0 & -1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1
\end{bmatrix},
\quad
Z =
\begin{bmatrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},
\]
the relative camera pose can be recovered as
\[
R \in \{ U W V^\top,\; U W^\top V^\top \},
\quad
[t]_\times = U Z U^\top
\]

This decomposition yields four candidate solutions for \((R, t)\), arising from
a two-fold ambiguity in the rotation and an unknown sign of the translation
vector. The translation \(t\) is recovered only up to an unknown scale factor,
which cannot be resolved from two-view geometry alone.

\paragraph{Cheirality condition.}
The physically valid solution is selected by enforcing the cheirality condition:
triangulated 3D points must lie in front of both cameras. Concretely, a point satisfies the cheirality condition if its depth is positive in the coordinate frames of both cameras. Only one candidate solution satisfies this constraint.

\section{Triangulation}

Given camera projection matrices \(P_1, P_2\) and corresponding homogeneous image points \(x_1, x_2\), the 3D point \(X\) satisfies the epipolar consistency conditions
\[
x_i \times (P_i X) = 0, \quad i = 1,2
\]

Each cross product yields two independent linear equations. Stacking these constraints produces a homogeneous linear system
\[
A X = 0
\]
which is solved using singular value decomposition. The solution is defined up to scale.

In practice, triangulation is performed using camera projection matrices expressed in a common coordinate frame, typically constructed from normalised image coordinates or full projection matrices of the form:
\(P_i = K_i [R_i \mid t_i]\)

\end{document}
